{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ebc84-0f1e-405a-b7b9-f9de92591466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from dassl.config import get_cfg_default\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim \n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from dassl.data.datasets.build import build_dataset\n",
    "from dassl.data.transforms.transforms import build_transform\n",
    "from dassl.data.data_manager import build_data_loader\n",
    "\n",
    "import FSL.datasets.stanford_cars\n",
    "import FSL.datasets.stanford_dogs\n",
    "import FSL.datasets.caltech101\n",
    "import FSL.datasets.oxford_flowers\n",
    "import FSL.datasets.oxford_pets\n",
    "import FSL.datasets.food101\n",
    "import FSL.datasets.eurosat\n",
    "import FSL.datasets.sun397\n",
    "import FSL.datasets.fgvc_aircraft\n",
    "import FSL.datasets.cub\n",
    "import FSL.datasets.ucf101\n",
    "import FSL.datasets.plantdoc\n",
    "import FSL.datasets.imagenet\n",
    "\n",
    "from utils.eval_utils import *\n",
    "import utils.ssd as ssd\n",
    "\n",
    "\n",
    "all_ds = ['StanfordDogs', 'StanfordCars',  'Caltech101', 'OxfordFlowers', 'Food101', 'DescribableTextures', 'EuroSAT', 'SUN397', 'FGVCAircraft', 'CUB', 'UCF101', 'PLANTDOC']\n",
    "val_ds = [ 'EuroSAT', 'SUN397','Food101', 'DescribableTextures','PLANTDOC']\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "cfg = get_cfg_default()\n",
    "\n",
    "cfg.merge_from_file(\"configs/trainers/mainconfig/adam_lr2e-4_B256_ep200_ViT16.yaml\")\n",
    "\n",
    "cfg.DATASET.SUBSAMPLE_CLASSES = \"all\"\n",
    "cfg.SEED = 0\n",
    "cfg.DATASET.ROOT = \"/app/datasets/\"\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "# cfg.USE_CUDA = False\n",
    "cfg.DATASET.NUM_SHOTS = -1\n",
    "\n",
    "cfg.DATALOADER.TRAIN_X.BATCH_SIZE = 4\n",
    "cfg.DATALOADER.TEST.BATCH_SIZE = 16\n",
    "\n",
    "backbone_arch = \"ViT-B/16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8452e6d-c7fe-4d0d-a326-8ce1bef731f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503eae62-dd81-43ad-af84-d9b1007224a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b91625-d52d-4e40-b81c-01a9be7f7dec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_datasets = {}\n",
    "test_dataloaders = {}\n",
    "train_loaders = {}\n",
    "datasets_cls = {}\n",
    "classnames = {}\n",
    "\n",
    "cfg_original = copy.deepcopy(cfg)\n",
    "for ds in all_ds:\n",
    "    cfg = copy.deepcopy(cfg_original)\n",
    "    cfg.DATASET.NAME = ds\n",
    "    tfm_train = build_transform(cfg, is_train=True)\n",
    "    tfm_test = build_transform(cfg, is_train=False)\n",
    "\n",
    "    dataset = build_dataset(cfg)\n",
    "    test_loader_all = build_data_loader(\n",
    "                cfg,\n",
    "                sampler_type=cfg.DATALOADER.TEST.SAMPLER,\n",
    "                data_source=dataset.test,\n",
    "                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,\n",
    "                tfm=tfm_test,\n",
    "                is_train=False,\n",
    "                dataset_wrapper=None\n",
    "            )\n",
    "\n",
    "    train_loader_all = build_data_loader(\n",
    "                cfg,\n",
    "                sampler_type='RandomSampler',\n",
    "                data_source=dataset.train_x,\n",
    "                batch_size=64,\n",
    "                tfm = tfm_test,\n",
    "                is_train=False,\n",
    "                dataset_wrapper=None\n",
    "            )\n",
    "\n",
    "    test_datasets[ds] = dataset\n",
    "    test_dataloaders[ds] = test_loader_all\n",
    "    train_loaders[ds] = train_loader_all\n",
    "    datasets_cls[ds] = dataset\n",
    "    classnames[ds] = dataset.classnames\n",
    "\n",
    "\n",
    "with open(f\"assets/results_zs_all_ViT16.pkl\", \"rb\") as f:\n",
    "    results_zs = pickle.load(f)  \n",
    "\n",
    "myseed=cfg.SEED\n",
    "torch.manual_seed(myseed)\n",
    "random.seed(myseed)\n",
    "np.random.seed(myseed)\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be70b81-f045-40f8-b10b-2b172d3d7264",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "552d7e85-f730-42c0-91d4-12b045aa72ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example of forgetting with SSD on StanfordDogs dataset\n",
    "##### Compute importances for SSD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ac09e-ca3c-4ee2-9b14-cab0d73fd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed importances for all datasets\n",
    "\n",
    "dampening_constant = 1.\n",
    "selection_weighting = 30.\n",
    "parameters = {\n",
    "        \"lower_bound\": 1.,  # 1\n",
    "        \"exponent\": 1.,  # unused\n",
    "        \"magnitude_diff\": None,  # unused\n",
    "        \"min_layer\": -1,  # -1: all layers are available for modification\n",
    "        \"max_layer\": -1,  # -1: all layers are available for modification\n",
    "        \"forget_threshold\": 1,  # unused\n",
    "        \"dampening_constant\": dampening_constant,  # Lambda from paper\n",
    "        \"selection_weighting\": selection_weighting,  # Alpha from paper\n",
    "        \"batch_size\" : 64 # Important for importance calculations as quite sensitive!\n",
    "    }\n",
    "\n",
    "retain_loader = {\n",
    "                     'StanfordDogs' : train_loaders['StanfordDogs'], \n",
    "                     'StanfordCars': train_loaders['StanfordCars'], \n",
    "                     'Caltech101': train_loaders['Caltech101'], \n",
    "                     'OxfordFlowers' : train_loaders['OxfordFlowers'], \n",
    "    \n",
    "                     'CUB': train_loaders['CUB'], \n",
    "                     'UCF101' : train_loaders['UCF101'], \n",
    "    \n",
    "                     'FGVCAircraft': train_loaders['FGVCAircraft'], \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ec102-025e-425a-b849-86ea9731f9b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model(device=device, arch=backbone_arch)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "pdr = ssd.ParameterPerturber(model, optimizer, device, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2adb0-8d1c-433c-8a3a-8c23d453749e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_importances = pdr.calc_importance(retain_loader, classnames, aggregate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462904c-a84b-4342-a843-bac44dbff4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_all = {}\n",
    "for file in os.listdir(\"ssd_importances/\"):\n",
    "    if file.startswith(\"importance\"):\n",
    "        ds = torch.load(f\"ssd_importances/{file}\")\n",
    "        ds_name = file.split(\"_\")[1].replace(\".pt\", \"\")\n",
    "        print(ds_name)\n",
    "        importances_all[ds_name] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684cb77-1148-4a54-802e-267bf1d37e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(importances_all, f\"ssd_importances/all_importances_batch_64.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6a0f0-e95f-4ece-8be7-5c29c8074e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d8e8b1-79b8-4044-b4a6-7d02ea61c5c3",
   "metadata": {},
   "source": [
    "##### Unlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f095c9-60ec-426b-bdea-c5260bb2309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_ds = 'StanfordDogs'\n",
    "id_test = 0\n",
    "forget_loader = {forget_ds : train_loaders[forget_ds]}\n",
    "\n",
    "retain_loader = {\n",
    "                     'Caltech101': train_loaders['Caltech101'], \n",
    "                     'OxfordFlowers' : train_loaders['OxfordFlowers'], \n",
    "                     'CUB': train_loaders['CUB'],     \n",
    "                }\n",
    "\n",
    "retain_ds = '|'.join([k for k in retain_loader.keys()])\n",
    "                 \n",
    "full_name = f\"forget_{forget_ds}_retain_{retain_ds}_attempt_{id_test}\"\n",
    "\n",
    "forget_list = list(forget_loader.keys())\n",
    "retain_list = list(retain_loader.keys())\n",
    "    \n",
    "full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65ec93-8e25-475b-99ae-70215354f61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc59dc6-a500-46da-b485-49aff53e6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = f\"ssd_importances/all_importances_batch_64.pt\"\n",
    "path = f\"/app/few_shot_unlearning_old/ssd_importances/all_importances_batch_64.pt\"\n",
    "# Calculation of the forget set importances\n",
    "sample_importances = pdr.calc_importance_loaded(path, forget_list)\n",
    "\n",
    "# Calculate the importances of the retain sets\n",
    "original_importances = pdr.calc_importance_loaded(path, retain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f726a-a775-42b5-bc8b-150a9757a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "\n",
    "dampening_constant = 1.\n",
    "selection_weighting = 30.\n",
    "parameters = {\n",
    "        \"lower_bound\": 1.,  # 1\n",
    "        \"exponent\": 1.,  # unused\n",
    "        \"magnitude_diff\": None,  # unused\n",
    "        \"min_layer\": -1,  # -1: all layers are available for modification\n",
    "        \"max_layer\": -1,  # -1: all layers are available for modification\n",
    "        \"forget_threshold\": 1,  # unused\n",
    "        \"dampening_constant\": dampening_constant,  # Lambda from paper\n",
    "        \"selection_weighting\": selection_weighting,  # Alpha from paper\n",
    "        \"batch_size\" : 64 # Important for importance calculations as quite sensitive!\n",
    "    }\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "model = get_model(device=device, arch=backbone_arch)\n",
    "model = model.eval()\n",
    "\n",
    "pdr = ssd.ParameterPerturber(model, optimizer, device, parameters)\n",
    "\n",
    "# Dampen selected parameters\n",
    "pdr.modify_weight(original_importances, sample_importances, ignore_params=['logit_scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0603d-da86-4876-bda5-ab6ee4263b1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results_ds = eval_all_ds(model, datasets_cls, test_dataloaders, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8bfd9-2cdb-425f-a9eb-12e171152eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5398a-e82d-4847-8501-9948bf243c0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1425a9e7-bef4-46c0-a5dd-52c193f661ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute MMD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acf1ae-d1db-4a9a-ba31-3271d030611a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model(device=device, arch=backbone_arch)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262bc0d-44a3-40ba-8d59-e60f7cbb6314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b836136-6697-48db-b72b-c96d04bb06e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "with torch.no_grad():\n",
    "    for key in train_loaders:\n",
    "        if key != 'ImageNet': continue\n",
    "        print(key)\n",
    "        features = {'text' : \"\", 'images' : []}\n",
    "        ds_loader = train_loaders[key]\n",
    "        for batch in tqdm(ds_loader):\n",
    "            img = batch['img'].cuda()\n",
    "            features['images'].append(model.encode_image(img).detach().cpu().numpy().squeeze())\n",
    "\n",
    "        features['images'] = np.concatenate(features['images'])\n",
    "        features['text'] = model.encode_text(clip.tokenize(datasets_cls[key].classnames).cuda())#.detach().cpu().numpy()\n",
    "\n",
    "        with open(f\"features_embeddings/features_{key}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0511506-1cad-42db-8487-8c8800fa375d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmd_similarities = {}\n",
    "\n",
    "main_path = f\"features_embeddings/features\"\n",
    "\n",
    "for key1 in tqdm(train_loaders):\n",
    "    for key2 in train_loaders:\n",
    "        key_ds = '_'.join(sorted([key1, key2]))\n",
    "        if key1 != key2 and key_ds not in mmd_similarities:\n",
    "            with open(f\"{main_path}_{key1}.pkl\", \"rb\") as f:\n",
    "                feat_key1 = pickle.load(f)\n",
    "            with open(f\"{main_path}_{key2}.pkl\", \"rb\") as f:\n",
    "                feat_key2 = pickle.load(f)\n",
    "                \n",
    "            mmd_similarities[key_ds] = mmd_rbf(feat_key1['images'], feat_key2['images'], gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e9eae-91ec-4133-85e1-608d0f547947",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_similarities_text = {}\n",
    "\n",
    "for key1 in tqdm(train_loaders):\n",
    "    for key2 in train_loaders:\n",
    "        key_ds = '_'.join(sorted([key1, key2]))\n",
    "        if key1 != key2 and key_ds not in mmd_similarities_text:\n",
    "            with open(f\"{main_path}_{key1}.pkl\", \"rb\") as f:\n",
    "                feat_key1 = pickle.load(f)\n",
    "            with open(f\"{main_path}_{key2}.pkl\", \"rb\") as f:\n",
    "                feat_key2 = pickle.load(f)\n",
    "                \n",
    "            mmd_similarities_text[key_ds] = mmd_rbf(feat_key1['text'].detach().cpu().numpy(), feat_key2['text'].detach().cpu().numpy(), gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29023690-159a-4c61-8824-3824dcc75469",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"features_embeddings/mmd_sim_images.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mmd_similarities, f)\n",
    "    \n",
    "with open(f\"features_embeddings/mmd_sim_text.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mmd_similarities_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f874b2-921b-4977-9354-fdee8726a26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bc2f9-7c33-452c-b584-a672baa956b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"features_embeddings/mmd_sim_images.pkl\", \"rb\") as f:\n",
    "    mmd_similarities = pickle.load(f)\n",
    "    \n",
    "with open(f\"features_embeddings/mmd_sim_text.pkl\", \"rb\") as f:\n",
    "    mmd_similarities_text = pickle.load(f)\n",
    "\n",
    "zs_clip_results =  {\n",
    "    \"EuroSAT\": 48.383,\n",
    "    \"StanfordCars\": 65.514,\n",
    "    \"PLANTDOC\": 34.994,\n",
    "    \"DescribableTextures\": 43.972,\n",
    "    \"StanfordDogs\": 59.117,\n",
    "    \"SUN397\": 62.579,\n",
    "    \"FGVCAircraft\": 24.752,\n",
    "    \"CUB\": 55.009,\n",
    "    \"Caltech101\": 93.306,\n",
    "    \"Food101\": 85.888,\n",
    "    \"UCF101\": 67.46,\n",
    "    \"OxfordFlowers\": 70.767\n",
    "}\n",
    "\n",
    "weights = weighted_loss(forget_ds, val_ds, mmd_similarities_text, mmd_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca6e1d-4736-41a1-91cc-5b7df8284e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3b56b-9c1e-4d43-a3f1-5fb8b909a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = {}\n",
    "for k in zs_clip_results:\n",
    "    if k != forget_ds:\n",
    "        print(k, round(max(zs_clip_results[k] - results_ds[k]['all']['all_ds']*100, 0), 3))\n",
    "        diff[k] = zs_clip_results[k] - results_ds[k]['all']['all_ds']*100\n",
    "        \n",
    "# difference on validation sets (list knowledge of CLIP)\n",
    "np.sum([diff[k] * weights[k] for k in val_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b2b7e-a877-4765-94cf-bffde90ea938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a240f-7119-46c2-a0d6-9aa326beaff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
